{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = pd.read_csv('NSL_regular_season_data_2.csv')\n",
    "season = season.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming season is already sorted by game_id\n",
    "total_games = season.shape[0]\n",
    "split_index = int(total_games * 756/952)  # Aprox. 79% split (so every team plays ~27 games in training data)\n",
    "# Split the dataset\n",
    "season_X = season.iloc[:split_index].copy()\n",
    "season_y = season.iloc[split_index:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = list(set(season_X[\"HomeTeam\"]).union(set(season_X[\"AwayTeam\"])))\n",
    "ratings = {team: 1500 for team in all_teams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update_elo() missing 1 required positional argument: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings_forward\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m season\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 33\u001b[0m     \u001b[43mupdate_elo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAwayTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAwayScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHome_xG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAway_xG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Update ratings_reverse with the reverse iteration\u001b[39;00m\n\u001b[1;32m     36\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings_reverse\n",
      "\u001b[0;31mTypeError\u001b[0m: update_elo() missing 1 required positional argument: 'c'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize team ratings for both models\n",
    "teams = pd.concat([season['HomeTeam'], season['AwayTeam']]).unique()\n",
    "ratings_forward = {team: 1500 for team in teams}\n",
    "ratings_reverse = {team: 1500 for team in teams}\n",
    "\n",
    "# Home field advantage constant\n",
    "HOME_ADVANTAGE = 100\n",
    "\n",
    "# Elo rating function with home field advantage and xG difference\n",
    "def update_elo(home_team, away_team, home_score, away_score, home_xG, away_xG, K, c):\n",
    "    # Adjust home team rating for home advantage\n",
    "    adjusted_home_rating = ratings[home_team] + HOME_ADVANTAGE\n",
    "    \n",
    "    # Calculate expected scores\n",
    "    E_home = 1 / (1 + 10 ** ((ratings[away_team] - adjusted_home_rating) / c))\n",
    "    E_away = 1 - E_home\n",
    "\n",
    "    # Determine actual score\n",
    "    S_home, S_away = (1, 0) if home_xG > away_xG else (0, 1) if home_xG < away_xG else (0.5, 0.5)\n",
    "    \n",
    "    # Calculate xG difference and adjust K factor\n",
    "    xG_diff = home_xG - away_xG\n",
    "    K_adjusted = K * (1 + abs(xG_diff) / 2)  # Example adjustment, modify as needed\n",
    "    \n",
    "    # Update ratings\n",
    "    ratings[home_team] += K_adjusted * (S_home - E_home)\n",
    "    ratings[away_team] += K_adjusted * (S_away - E_away)\n",
    "\n",
    "\n",
    "# Update ratings_forward with the forward iteration\n",
    "ratings = ratings_forward\n",
    "for index, row in season.iterrows():\n",
    "    update_elo(row['HomeTeam'], row['AwayTeam'], row['HomeScore'], row['AwayScore'], row['Home_xG'], row['Away_xG'], 10)\n",
    "\n",
    "# Update ratings_reverse with the reverse iteration\n",
    "ratings = ratings_reverse\n",
    "for index in range(season.shape[0] - 1, -1, -1):\n",
    "    row = season.iloc[index]\n",
    "    update_elo(row['HomeTeam'], row['AwayTeam'], row['HomeScore'], row['AwayScore'], row['Home_xG'], row['Away_xG'], 10)\n",
    "\n",
    "# Create a DataFrame to store both sets of ratings and calculate the difference\n",
    "ratings_df = pd.DataFrame(index=teams, columns=['EloRating', 'Reverse Rating', 'Difference'])\n",
    "for team in teams:\n",
    "    ratings_df.at[team, 'EloRating'] = ratings_forward[team]\n",
    "    ratings_df.at[team, 'Reverse Rating'] = ratings_reverse[team]\n",
    "    ratings_df.at[team, 'Difference'] = ratings_forward[team] - ratings_reverse[team]\n",
    "    ratings_df.at[team, \"team_name\"] = team\n",
    "\n",
    "# Print the DataFrame\n",
    "print(ratings_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/mbrk18t13kqg1n0nk8535q440000gn/T/ipykernel_67392/715305827.py:8: RuntimeWarning: overflow encountered in scalar power\n",
      "  E_home = 1 / (1 + 10 ** ((ratings[away_team] - adjusted_home_rating) / c))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k factor: 9.296320093074655\n",
      "best hfa factor: 222.58689739303236\n",
      "best c factor: 32.29228319753929\n",
      "best b factor: 5.006446168539377\n",
      "rmse 0.28001664107779356\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "def update_elo(home_team, away_team, home_xG, away_xG, K, c, HFA,b):\n",
    "    # Adjust home team rating for home advantage\n",
    "    adjusted_home_rating = ratings[home_team] + HFA\n",
    "    \n",
    "    E_home = 1 / (1 + 10 ** ((ratings[away_team] - adjusted_home_rating) / c))\n",
    "    E_away = 1 - E_home\n",
    "\n",
    "    S_home, S_away = (1, 0) if home_xG > away_xG else (0, 1) if home_xG < away_xG else (0.5, 0.5)\n",
    "    \n",
    "    xG_diff = home_xG - away_xG\n",
    "    K_adjusted = K * (1 + abs(xG_diff) / b)\n",
    "    \n",
    "    # Update ratings\n",
    "    ratings[home_team] += K_adjusted * (S_home - E_home)\n",
    "    ratings[away_team] += K_adjusted * (S_away - E_away)\n",
    "    squared_error = np.sqrt ((E_home - S_home) ** 2)\n",
    "    #print (squared_errors)\n",
    "    return squared_error\n",
    "\n",
    "def objective_function(params, home, away, homeXG, awayXG):\n",
    "    k, hfa, c, b = params\n",
    "     \n",
    "    squared_errors = []\n",
    "    for index, row in season_X.iterrows():\n",
    "        squared_errors.append( update_elo(row['HomeTeam'], row['AwayTeam'], row['Home_xG'], row['Away_xG'], k, c, hfa, b))\n",
    "    return (np.mean(squared_errors))\n",
    "p0 = [10, 100, 400, 2]  \n",
    "bounds = [(0, 100), (0, 100),(300, 500), (0,10)]\n",
    "\n",
    "result = minimize(objective_function, p0, args=(row['HomeTeam'], row['AwayTeam'], row['Home_xG'], row['Away_xG']),method=\"Nelder-Mead\")\n",
    "\n",
    "\n",
    "k, hfa, c, b = result.x\n",
    "\n",
    "print(\"best k factor:\", k)\n",
    "print(\"best hfa factor:\", hfa)\n",
    "print (\"best c factor:\", c)\n",
    "print(\"best b factor:\", b)\n",
    "print (\"rmse\", result.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TUC': 1521.9720735589165, 'FAR': 1500.0000156434055, 'MAN': 1478.3807100115002, 'ANC': 1500.000083229581, 'DOV': 1479.0677254033037, 'OAK': 1500.000013438018, 'BAK': 1490.5180132412952, 'SAS': 1500.0000082005356, 'SJU': 1500.519887891592, 'LAR': 1490.0724547243092, 'WIC': 1519.5952759391216, 'AUG': 1500.0000837838334, 'DES': 1500.0000162842578, 'ALB': 1478.7520933980775, 'LEX': 1500.000072548688, 'EUG': 1488.7539824441094, 'LRO': 1500.000037157934, 'SPR': 1521.8049513290039, 'TOL': 1551.7360527164547, 'CHM': 1500.0000623867938, 'TAC': 1499.3128923087984, 'BOI': 1500.0000149555817, 'FOR': 1500.0000211040224, 'PRO': 1500.0000282005765, 'REN': 1500.00001058065, 'SFS': 1500.0000235247287, 'MOB': 1488.9953899031193, 'JAC': 1490.5180060917924}\n"
     ]
    }
   ],
   "source": [
    "ratings = {team: 1500 for team in all_teams}\n",
    "for index, row in season_y.iterrows():\n",
    "    update_elo(row['HomeTeam'], row['AwayTeam'], row['Home_xG'], row['Away_xG'], k, c, hfa, b)\n",
    "print (ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOV', 'SAS', 'JAC', 'LRO']\n"
     ]
    }
   ],
   "source": [
    "sorted_items = sorted(ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_4_keys = [item[0] for item in sorted_items[:4]]\n",
    "\n",
    "print(top_4_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "\n",
    "\n",
    "# Merge for home team's Elo rating\n",
    "merged_df = pd.merge(season_y, ratings_df, left_on='HomeTeam', right_on='team_name', how='left')\n",
    "\n",
    "# Merge for away team's Elo rating\n",
    "merged_df = pd.merge(merged_df, ratings_df, left_on='AwayTeam', right_on='team_name', how='left', suffixes=('_home', '_away'))\n",
    "\n",
    "# Manually rename columns to avoid conflicts\n",
    "merged_df.rename(columns={'elo_rating_home': 'home_elo_rating', 'reverse_rating_home': 'home_reverse_rating', 'difference_home': 'home_difference',\n",
    "                          'elo_rating_away': 'away_elo_rating', 'reverse_rating_away': 'away_reverse_rating', 'difference_away': 'away_difference'}, inplace=True)\n",
    "\n",
    "# Drop redundant columns\n",
    "#merged_df.drop(['team_name_x', 'team_name_y'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          game_id HomeTeam AwayTeam  HomeScore  AwayScore  Home_xG  Away_xG  \\\n",
      "0   game_2023_248      DOV      SJU          3          0     1.74     1.06   \n",
      "1    game_2023_17      LEX      SJU          0          0     0.49     0.28   \n",
      "2   game_2023_117      CHM      SJU          3          1     1.52     0.32   \n",
      "3   game_2023_337      LAR      SJU          1          0     1.51     0.49   \n",
      "4   game_2023_201      MAN      SJU          3          7     1.26     2.03   \n",
      "5   game_2023_315      DES      SJU          1          1     1.36     0.35   \n",
      "6   game_2023_347      FAR      SJU          4          1     2.09     0.32   \n",
      "7   game_2023_378      LRO      SJU          3          0     3.27     0.47   \n",
      "8   game_2023_144      PRO      SJU          2          0     0.91     0.23   \n",
      "9   game_2023_450      JAC      SJU          0          0     2.13     0.34   \n",
      "10   game_2023_43      MOB      SJU          0          1     0.57     1.49   \n",
      "11  game_2023_408      BOI      SJU          0          0     1.39     0.06   \n",
      "12  game_2023_384      AUG      SJU          3          0     2.91     0.33   \n",
      "13  game_2023_329      SJU      SPR          2          3     0.63     2.02   \n",
      "14  game_2023_121      MAN      SPR          0          0     1.44     1.03   \n",
      "15  game_2023_173      PRO      SPR          1          2     1.47     0.54   \n",
      "16  game_2023_110      TOL      SPR          3          1     1.35     0.70   \n",
      "17  game_2023_300      FOR      SPR          1          0     2.15     0.14   \n",
      "18  game_2023_193      DES      SPR          1          4     1.12     0.73   \n",
      "19  game_2023_224      FAR      SPR          4          1     1.50     0.14   \n",
      "20  game_2023_390      JAC      SPR          5          2     2.45     0.15   \n",
      "21  game_2023_437      AUG      SPR          2          1     2.01     0.44   \n",
      "22  game_2023_476      WIC      SPR          1          1     1.73     0.57   \n",
      "23  game_2023_352      LRO      SPR          1          2     2.53     1.39   \n",
      "24  game_2023_453      CHM      SPR          2          2     1.73     1.06   \n",
      "25   game_2023_68      LAR      SPR          0          2     1.17     1.51   \n",
      "26  game_2023_242      TAC      SPR          7          0     3.01     1.17   \n",
      "27   game_2023_24      MOB      SPR          1          0     1.42     0.70   \n",
      "28  game_2023_259      LEX      SPR          0          0     1.40     0.53   \n",
      "29  game_2023_149      DOV      SPR          4          4     2.74     1.95   \n",
      "30  game_2023_403      SFS      TAC          2          2     1.86     0.91   \n",
      "31   game_2023_97      FAR      TAC          3          0     3.07     0.24   \n",
      "32   game_2023_13      LRO      TAC          1          1     2.17     0.23   \n",
      "33  game_2023_151      ALB      TAC          1          0     1.66     0.56   \n",
      "34  game_2023_270      BAK      TAC          3          0     0.31     0.41   \n",
      "35  game_2023_285      BOI      TAC          2          1     1.60     0.45   \n",
      "36  game_2023_176      WIC      TAC          1          0     1.46     1.23   \n",
      "37  game_2023_472      SAS      TAC          1          2     0.71     0.51   \n",
      "38  game_2023_261      JAC      TAC          2          0     2.06     0.70   \n",
      "39  game_2023_136      AUG      TAC          2          1     2.51     1.46   \n",
      "40   game_2023_71      EUG      TAC          0          3     1.52     2.57   \n",
      "41   game_2023_37      ANC      TAC          3          1     3.05     0.81   \n",
      "42  game_2023_221      REN      TAC          1          1     1.65     0.40   \n",
      "43  game_2023_417      TUC      TAC          3          7     2.41     0.70   \n",
      "44  game_2023_343      FOR      TAC          3          1     2.89     0.90   \n",
      "45  game_2023_211      OAK      TAC          1          0     2.08     0.37   \n",
      "46   game_2023_52      MAN      TAC          4          1     1.84     0.09   \n",
      "47  game_2023_415      DOV      TOL          2          1     0.74     1.77   \n",
      "48  game_2023_171      FOR      TOL          1          3     2.07     0.99   \n",
      "49  game_2023_148      MOB      TOL          1          2     2.18     1.17   \n",
      "50  game_2023_132      JAC      TOL          3          1     0.53     0.63   \n",
      "51  game_2023_312      SJU      TOL          2          3     1.41     1.43   \n",
      "52  game_2023_460      PRO      TOL          3          0     3.13     0.61   \n",
      "53  game_2023_365      DES      TOL          1          2     1.22     1.17   \n",
      "54   game_2023_48      SFS      TOL          2          1     1.63     1.05   \n",
      "55   game_2023_22      MAN      TOL          3          1     0.67     1.53   \n",
      "56  game_2023_340      SPR      TOL          1          2     1.46     0.98   \n",
      "57  game_2023_284      LRO      TOL          3          0     1.93     0.54   \n",
      "58   game_2023_58      ALB      TOL          1          2     1.09     1.91   \n",
      "59  game_2023_265      ANC      TOL          1          0     2.40     0.71   \n",
      "60  game_2023_197      LAR      TOL          0          0     1.36     0.86   \n",
      "61   game_2023_92      CHM      TOL          2          1     1.88     0.81   \n",
      "62  game_2023_212      LEX      TOL          0          3     1.70     0.18   \n",
      "63  game_2023_457      AUG      TOL          1          0     2.11     0.21   \n",
      "64  game_2023_399      REN      TUC          2          0     1.60     0.46   \n",
      "65  game_2023_183      BOI      TUC          3          1     3.72     0.20   \n",
      "66   game_2023_18      TAC      TUC          1          3     0.90     2.11   \n",
      "67  game_2023_440      FAR      TUC          1          0     0.84     0.34   \n",
      "68  game_2023_169      SFS      TUC          4          1     2.38     0.80   \n",
      "69  game_2023_101      SAS      TUC          1          0     1.44     0.65   \n",
      "70  game_2023_305      DOV      TUC          1          3     1.84     1.04   \n",
      "71  game_2023_319      EUG      TUC          2          0     1.34     0.78   \n",
      "72  game_2023_455      OAK      TUC          2          0     1.07     0.67   \n",
      "73  game_2023_130      SJU      TUC          5          4     3.29     1.15   \n",
      "74  game_2023_202      TOL      TUC          4          1     2.33     0.11   \n",
      "75  game_2023_262      FOR      TUC          2          2     2.24     1.05   \n",
      "76  game_2023_227      ALB      TUC          3          3     0.51     1.12   \n",
      "77  game_2023_281      WIC      TUC          0          0     1.17     0.43   \n",
      "78   game_2023_63      PRO      TUC          4          0     1.61     0.65   \n",
      "79  game_2023_371      BAK      TUC          2          1     1.62     0.32   \n",
      "80  game_2023_356      ANC      TUC          0          1     1.59     0.83   \n",
      "81  game_2023_376      TAC      WIC          0          3     1.32     1.63   \n",
      "82  game_2023_150      EUG      WIC          2          1     1.58     0.45   \n",
      "83  game_2023_331      FOR      WIC          3          0     3.04     1.06   \n",
      "84  game_2023_342      SAS      WIC          2          0     0.83     0.36   \n",
      "85  game_2023_260      MOB      WIC          2          0     1.91     0.88   \n",
      "86   game_2023_51      BAK      WIC          1          2     1.45     1.15   \n",
      "87  game_2023_471      REN      WIC          2          2     1.97     1.56   \n",
      "88  game_2023_188      FAR      WIC          4          1     3.33     0.40   \n",
      "89  game_2023_124      AUG      WIC          3          1     2.61     1.03   \n",
      "90  game_2023_194      OAK      WIC          5          0     2.78     0.47   \n",
      "91  game_2023_416      LEX      WIC          2          2     2.41     1.89   \n",
      "92  game_2023_205      BOI      WIC          1          3     2.36     1.20   \n",
      "93   game_2023_81      TUC      WIC          2          1     2.72     0.38   \n",
      "94   game_2023_36      DOV      WIC          0          2     1.11     1.34   \n",
      "95  game_2023_269      SFS      WIC          1          1     2.84     0.30   \n",
      "96  game_2023_298      ALB      WIC          2          3     2.61     2.09   \n",
      "97  game_2023_428      ANC      WIC          1          0     0.94     0.27   \n",
      "\n",
      "    Home_shots  Away_shots  Home_corner  ...  Away_PK_shots  Home_ToP  \\\n",
      "0           18          14            6  ...              0      0.54   \n",
      "1           12           9            3  ...              0      0.49   \n",
      "2           19           6            2  ...              0      0.43   \n",
      "3            4          19            8  ...              0      0.43   \n",
      "4           12           9            7  ...              0      0.53   \n",
      "5            7           4           16  ...              0      0.55   \n",
      "6           15          10            7  ...              1      0.62   \n",
      "7           20          15            6  ...              0      0.59   \n",
      "8            4           6            9  ...              0      0.57   \n",
      "9           15           6            3  ...              0      0.65   \n",
      "10           5           9            9  ...              0      0.50   \n",
      "11          15          13            2  ...              0      0.53   \n",
      "12          17           5            3  ...              1      0.61   \n",
      "13           6          18            6  ...              0      0.53   \n",
      "14          18          11            2  ...              0      0.44   \n",
      "15          14           5            9  ...              0      0.47   \n",
      "16          13          15            5  ...              0      0.64   \n",
      "17          21          13            7  ...              0      0.77   \n",
      "18           8          11            4  ...              0      0.61   \n",
      "19           6          16           11  ...              0      0.53   \n",
      "20          12          16            1  ...              0      0.66   \n",
      "21          21           6            3  ...              0      0.56   \n",
      "22          13           3            1  ...              0      0.56   \n",
      "23          11           7            3  ...              0      0.72   \n",
      "24          18          15            5  ...              0      0.68   \n",
      "25          16          13           11  ...              0      0.66   \n",
      "26          20          15            5  ...              0      0.63   \n",
      "27          15           6            6  ...              1      0.67   \n",
      "28          14           7            6  ...              0      0.45   \n",
      "29          20          14            6  ...              0      0.60   \n",
      "30          15          14            1  ...              0      0.60   \n",
      "31          26          17           10  ...              0      0.52   \n",
      "32          13           5            8  ...              1      0.44   \n",
      "33          17          10            5  ...              1      0.41   \n",
      "34          12           4            7  ...              0      0.53   \n",
      "35           6           8            5  ...              0      0.56   \n",
      "36          11          11            6  ...              0      0.63   \n",
      "37          19          12            7  ...              0      0.42   \n",
      "38          19           3            8  ...              0      0.64   \n",
      "39          19          12            6  ...              0      0.53   \n",
      "40          15          20            5  ...              0      0.48   \n",
      "41          17           5            6  ...              1      0.44   \n",
      "42          20          13            7  ...              0      0.49   \n",
      "43          17          12            6  ...              0      0.53   \n",
      "44          21          16            5  ...              0      0.62   \n",
      "45          11           4            8  ...              0      0.61   \n",
      "46          12           6            7  ...              0      0.54   \n",
      "47          12          17            4  ...              0      0.48   \n",
      "48          16          16            3  ...              0      0.71   \n",
      "49          20          11            9  ...              0      0.48   \n",
      "50           6           9            4  ...              0      0.59   \n",
      "51          10          17            6  ...              0      0.56   \n",
      "52          17           5            1  ...              0      0.40   \n",
      "53          17           5            3  ...              0      0.50   \n",
      "54          20          10            6  ...              0      0.62   \n",
      "55          19          18            9  ...              0      0.53   \n",
      "56          16          12            9  ...              0      0.48   \n",
      "57          15           9            3  ...              0      0.62   \n",
      "58           7          15           10  ...              0      0.52   \n",
      "59          18           9            3  ...              0      0.51   \n",
      "60          11           6            3  ...              0      0.53   \n",
      "61          15           8            3  ...              1      0.60   \n",
      "62          20           6            8  ...              0      0.46   \n",
      "63          20           9            9  ...              1      0.57   \n",
      "64           8           5            7  ...              0      0.63   \n",
      "65          18          13            6  ...              0      0.53   \n",
      "66          18          18            7  ...              0      0.58   \n",
      "67           2           1            6  ...              0      0.49   \n",
      "68          19          18           12  ...              0      0.73   \n",
      "69          15          14            7  ...              0      0.50   \n",
      "70          17          11            1  ...              2      0.50   \n",
      "71          13           6            2  ...              0      0.45   \n",
      "72          15          10            7  ...              0      0.53   \n",
      "73          17          12            6  ...              0      0.46   \n",
      "74          30           3            8  ...              0      0.46   \n",
      "75          15          13            6  ...              0      0.50   \n",
      "76           5           9            3  ...              0      0.40   \n",
      "77           4          10            8  ...              0      0.51   \n",
      "78          24          11            2  ...              0      0.54   \n",
      "79          23           8            4  ...              0      0.56   \n",
      "80          14          15            4  ...              0      0.51   \n",
      "81          21           9            7  ...              0      0.50   \n",
      "82          10           9            7  ...              1      0.39   \n",
      "83          20          17            6  ...              0      0.44   \n",
      "84          10           8            3  ...              0      0.38   \n",
      "85           5           5            3  ...              0      0.56   \n",
      "86           5          10            7  ...              0      0.38   \n",
      "87          19          15            7  ...              0      0.56   \n",
      "88          25           6           10  ...              0      0.45   \n",
      "89          17          13            4  ...              0      0.54   \n",
      "90          19          14            2  ...              0      0.53   \n",
      "91          22          17            9  ...              0      0.47   \n",
      "92          16          10            6  ...              0      0.35   \n",
      "93          16           8            8  ...              0      0.33   \n",
      "94           9          13            7  ...              0      0.31   \n",
      "95          26           2            8  ...              0      0.54   \n",
      "96          12          17            7  ...              0      0.43   \n",
      "97          15          16            3  ...              0      0.44   \n",
      "\n",
      "    EloRating_home  Reverse Rating_home  Difference_home  team_name_home  \\\n",
      "0      1552.800948          1562.803336       -10.002388             DOV   \n",
      "1      1481.719023          1473.016791         8.702232             LEX   \n",
      "2      1487.628992          1479.779595         7.849397             CHM   \n",
      "3      1536.498891          1530.814464         5.684428             LAR   \n",
      "4      1501.654574          1500.291117         1.363457             MAN   \n",
      "5      1517.445317          1519.282775        -1.837459             DES   \n",
      "6      1571.460631           1565.07689         6.383741             FAR   \n",
      "7      1545.139989          1535.389473         9.750516             LRO   \n",
      "8      1476.500028          1468.924638          7.57539             PRO   \n",
      "9      1548.466979          1545.435598         3.031382             JAC   \n",
      "10     1438.245266          1443.115063        -4.869796             MOB   \n",
      "11     1554.329626          1541.188906        13.140721             BOI   \n",
      "12     1525.149558          1506.981688         18.16787             AUG   \n",
      "13     1459.756113          1481.647968       -21.891855             SJU   \n",
      "14     1501.654574          1500.291117         1.363457             MAN   \n",
      "15     1476.500028          1468.924638          7.57539             PRO   \n",
      "16     1487.246063          1493.941722        -6.695659             TOL   \n",
      "17     1506.251649          1508.366195        -2.114547             FOR   \n",
      "18     1517.445317          1519.282775        -1.837459             DES   \n",
      "19     1571.460631           1565.07689         6.383741             FAR   \n",
      "20     1548.466979          1545.435598         3.031382             JAC   \n",
      "21     1525.149558          1506.981688         18.16787             AUG   \n",
      "22     1419.561996          1432.180697       -12.618701             WIC   \n",
      "23     1545.139989          1535.389473         9.750516             LRO   \n",
      "24     1487.628992          1479.779595         7.849397             CHM   \n",
      "25     1536.498891          1530.814464         5.684428             LAR   \n",
      "26      1442.36177          1467.867398       -25.505628             TAC   \n",
      "27     1438.245266          1443.115063        -4.869796             MOB   \n",
      "28     1481.719023          1473.016791         8.702232             LEX   \n",
      "29     1552.800948          1562.803336       -10.002388             DOV   \n",
      "30     1527.508114          1537.523145       -10.015031             SFS   \n",
      "31     1571.460631           1565.07689         6.383741             FAR   \n",
      "32     1545.139989          1535.389473         9.750516             LRO   \n",
      "33     1447.261902          1453.649609        -6.387706             ALB   \n",
      "34     1485.444498          1485.707103        -0.262605             BAK   \n",
      "35     1554.329626          1541.188906        13.140721             BOI   \n",
      "36     1419.561996          1432.180697       -12.618701             WIC   \n",
      "37     1556.830178          1559.405769        -2.575592             SAS   \n",
      "38     1548.466979          1545.435598         3.031382             JAC   \n",
      "39     1525.149558          1506.981688         18.16787             AUG   \n",
      "40     1440.705408          1426.454406        14.251001             EUG   \n",
      "41     1554.514159          1525.783839         28.73032             ANC   \n",
      "42     1514.168443          1522.389249        -8.220806             REN   \n",
      "43     1445.621169          1460.736081       -15.114911             TUC   \n",
      "44     1506.251649          1508.366195        -2.114547             FOR   \n",
      "45     1530.579608           1515.49343        15.086178             OAK   \n",
      "46     1501.654574          1500.291117         1.363457             MAN   \n",
      "47     1552.800948          1562.803336       -10.002388             DOV   \n",
      "48     1506.251649          1508.366195        -2.114547             FOR   \n",
      "49     1438.245266          1443.115063        -4.869796             MOB   \n",
      "50     1548.466979          1545.435598         3.031382             JAC   \n",
      "51     1459.756113          1481.647968       -21.891855             SJU   \n",
      "52     1476.500028          1468.924638          7.57539             PRO   \n",
      "53     1517.445317          1519.282775        -1.837459             DES   \n",
      "54     1527.508114          1537.523145       -10.015031             SFS   \n",
      "55     1501.654574          1500.291117         1.363457             MAN   \n",
      "56     1445.149105          1456.753054        -11.60395             SPR   \n",
      "57     1545.139989          1535.389473         9.750516             LRO   \n",
      "58     1447.261902          1453.649609        -6.387706             ALB   \n",
      "59     1554.514159          1525.783839         28.73032             ANC   \n",
      "60     1536.498891          1530.814464         5.684428             LAR   \n",
      "61     1487.628992          1479.779595         7.849397             CHM   \n",
      "62     1481.719023          1473.016791         8.702232             LEX   \n",
      "63     1525.149558          1506.981688         18.16787             AUG   \n",
      "64     1514.168443          1522.389249        -8.220806             REN   \n",
      "65     1554.329626          1541.188906        13.140721             BOI   \n",
      "66      1442.36177          1467.867398       -25.505628             TAC   \n",
      "67     1571.460631           1565.07689         6.383741             FAR   \n",
      "68     1527.508114          1537.523145       -10.015031             SFS   \n",
      "69     1556.830178          1559.405769        -2.575592             SAS   \n",
      "70     1552.800948          1562.803336       -10.002388             DOV   \n",
      "71     1440.705408          1426.454406        14.251001             EUG   \n",
      "72     1530.579608           1515.49343        15.086178             OAK   \n",
      "73     1459.756113          1481.647968       -21.891855             SJU   \n",
      "74     1487.246063          1493.941722        -6.695659             TOL   \n",
      "75     1506.251649          1508.366195        -2.114547             FOR   \n",
      "76     1447.261902          1453.649609        -6.387706             ALB   \n",
      "77     1419.561996          1432.180697       -12.618701             WIC   \n",
      "78     1476.500028          1468.924638          7.57539             PRO   \n",
      "79     1485.444498          1485.707103        -0.262605             BAK   \n",
      "80     1554.514159          1525.783839         28.73032             ANC   \n",
      "81      1442.36177          1467.867398       -25.505628             TAC   \n",
      "82     1440.705408          1426.454406        14.251001             EUG   \n",
      "83     1506.251649          1508.366195        -2.114547             FOR   \n",
      "84     1556.830178          1559.405769        -2.575592             SAS   \n",
      "85     1438.245266          1443.115063        -4.869796             MOB   \n",
      "86     1485.444498          1485.707103        -0.262605             BAK   \n",
      "87     1514.168443          1522.389249        -8.220806             REN   \n",
      "88     1571.460631           1565.07689         6.383741             FAR   \n",
      "89     1525.149558          1506.981688         18.16787             AUG   \n",
      "90     1530.579608           1515.49343        15.086178             OAK   \n",
      "91     1481.719023          1473.016791         8.702232             LEX   \n",
      "92     1554.329626          1541.188906        13.140721             BOI   \n",
      "93     1445.621169          1460.736081       -15.114911             TUC   \n",
      "94     1552.800948          1562.803336       -10.002388             DOV   \n",
      "95     1527.508114          1537.523145       -10.015031             SFS   \n",
      "96     1447.261902          1453.649609        -6.387706             ALB   \n",
      "97     1554.514159          1525.783839         28.73032             ANC   \n",
      "\n",
      "   EloRating_away Reverse Rating_away Difference_away team_name_away  \n",
      "0     1459.756113         1481.647968      -21.891855            SJU  \n",
      "1     1459.756113         1481.647968      -21.891855            SJU  \n",
      "2     1459.756113         1481.647968      -21.891855            SJU  \n",
      "3     1459.756113         1481.647968      -21.891855            SJU  \n",
      "4     1459.756113         1481.647968      -21.891855            SJU  \n",
      "5     1459.756113         1481.647968      -21.891855            SJU  \n",
      "6     1459.756113         1481.647968      -21.891855            SJU  \n",
      "7     1459.756113         1481.647968      -21.891855            SJU  \n",
      "8     1459.756113         1481.647968      -21.891855            SJU  \n",
      "9     1459.756113         1481.647968      -21.891855            SJU  \n",
      "10    1459.756113         1481.647968      -21.891855            SJU  \n",
      "11    1459.756113         1481.647968      -21.891855            SJU  \n",
      "12    1459.756113         1481.647968      -21.891855            SJU  \n",
      "13    1445.149105         1456.753054       -11.60395            SPR  \n",
      "14    1445.149105         1456.753054       -11.60395            SPR  \n",
      "15    1445.149105         1456.753054       -11.60395            SPR  \n",
      "16    1445.149105         1456.753054       -11.60395            SPR  \n",
      "17    1445.149105         1456.753054       -11.60395            SPR  \n",
      "18    1445.149105         1456.753054       -11.60395            SPR  \n",
      "19    1445.149105         1456.753054       -11.60395            SPR  \n",
      "20    1445.149105         1456.753054       -11.60395            SPR  \n",
      "21    1445.149105         1456.753054       -11.60395            SPR  \n",
      "22    1445.149105         1456.753054       -11.60395            SPR  \n",
      "23    1445.149105         1456.753054       -11.60395            SPR  \n",
      "24    1445.149105         1456.753054       -11.60395            SPR  \n",
      "25    1445.149105         1456.753054       -11.60395            SPR  \n",
      "26    1445.149105         1456.753054       -11.60395            SPR  \n",
      "27    1445.149105         1456.753054       -11.60395            SPR  \n",
      "28    1445.149105         1456.753054       -11.60395            SPR  \n",
      "29    1445.149105         1456.753054       -11.60395            SPR  \n",
      "30     1442.36177         1467.867398      -25.505628            TAC  \n",
      "31     1442.36177         1467.867398      -25.505628            TAC  \n",
      "32     1442.36177         1467.867398      -25.505628            TAC  \n",
      "33     1442.36177         1467.867398      -25.505628            TAC  \n",
      "34     1442.36177         1467.867398      -25.505628            TAC  \n",
      "35     1442.36177         1467.867398      -25.505628            TAC  \n",
      "36     1442.36177         1467.867398      -25.505628            TAC  \n",
      "37     1442.36177         1467.867398      -25.505628            TAC  \n",
      "38     1442.36177         1467.867398      -25.505628            TAC  \n",
      "39     1442.36177         1467.867398      -25.505628            TAC  \n",
      "40     1442.36177         1467.867398      -25.505628            TAC  \n",
      "41     1442.36177         1467.867398      -25.505628            TAC  \n",
      "42     1442.36177         1467.867398      -25.505628            TAC  \n",
      "43     1442.36177         1467.867398      -25.505628            TAC  \n",
      "44     1442.36177         1467.867398      -25.505628            TAC  \n",
      "45     1442.36177         1467.867398      -25.505628            TAC  \n",
      "46     1442.36177         1467.867398      -25.505628            TAC  \n",
      "47    1487.246063         1493.941722       -6.695659            TOL  \n",
      "48    1487.246063         1493.941722       -6.695659            TOL  \n",
      "49    1487.246063         1493.941722       -6.695659            TOL  \n",
      "50    1487.246063         1493.941722       -6.695659            TOL  \n",
      "51    1487.246063         1493.941722       -6.695659            TOL  \n",
      "52    1487.246063         1493.941722       -6.695659            TOL  \n",
      "53    1487.246063         1493.941722       -6.695659            TOL  \n",
      "54    1487.246063         1493.941722       -6.695659            TOL  \n",
      "55    1487.246063         1493.941722       -6.695659            TOL  \n",
      "56    1487.246063         1493.941722       -6.695659            TOL  \n",
      "57    1487.246063         1493.941722       -6.695659            TOL  \n",
      "58    1487.246063         1493.941722       -6.695659            TOL  \n",
      "59    1487.246063         1493.941722       -6.695659            TOL  \n",
      "60    1487.246063         1493.941722       -6.695659            TOL  \n",
      "61    1487.246063         1493.941722       -6.695659            TOL  \n",
      "62    1487.246063         1493.941722       -6.695659            TOL  \n",
      "63    1487.246063         1493.941722       -6.695659            TOL  \n",
      "64    1445.621169         1460.736081      -15.114911            TUC  \n",
      "65    1445.621169         1460.736081      -15.114911            TUC  \n",
      "66    1445.621169         1460.736081      -15.114911            TUC  \n",
      "67    1445.621169         1460.736081      -15.114911            TUC  \n",
      "68    1445.621169         1460.736081      -15.114911            TUC  \n",
      "69    1445.621169         1460.736081      -15.114911            TUC  \n",
      "70    1445.621169         1460.736081      -15.114911            TUC  \n",
      "71    1445.621169         1460.736081      -15.114911            TUC  \n",
      "72    1445.621169         1460.736081      -15.114911            TUC  \n",
      "73    1445.621169         1460.736081      -15.114911            TUC  \n",
      "74    1445.621169         1460.736081      -15.114911            TUC  \n",
      "75    1445.621169         1460.736081      -15.114911            TUC  \n",
      "76    1445.621169         1460.736081      -15.114911            TUC  \n",
      "77    1445.621169         1460.736081      -15.114911            TUC  \n",
      "78    1445.621169         1460.736081      -15.114911            TUC  \n",
      "79    1445.621169         1460.736081      -15.114911            TUC  \n",
      "80    1445.621169         1460.736081      -15.114911            TUC  \n",
      "81    1419.561996         1432.180697      -12.618701            WIC  \n",
      "82    1419.561996         1432.180697      -12.618701            WIC  \n",
      "83    1419.561996         1432.180697      -12.618701            WIC  \n",
      "84    1419.561996         1432.180697      -12.618701            WIC  \n",
      "85    1419.561996         1432.180697      -12.618701            WIC  \n",
      "86    1419.561996         1432.180697      -12.618701            WIC  \n",
      "87    1419.561996         1432.180697      -12.618701            WIC  \n",
      "88    1419.561996         1432.180697      -12.618701            WIC  \n",
      "89    1419.561996         1432.180697      -12.618701            WIC  \n",
      "90    1419.561996         1432.180697      -12.618701            WIC  \n",
      "91    1419.561996         1432.180697      -12.618701            WIC  \n",
      "92    1419.561996         1432.180697      -12.618701            WIC  \n",
      "93    1419.561996         1432.180697      -12.618701            WIC  \n",
      "94    1419.561996         1432.180697      -12.618701            WIC  \n",
      "95    1419.561996         1432.180697      -12.618701            WIC  \n",
      "96    1419.561996         1432.180697      -12.618701            WIC  \n",
      "97    1419.561996         1432.180697      -12.618701            WIC  \n",
      "\n",
      "[98 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print (merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m bounds \u001b[39m=\u001b[39m [(\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m), (\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m), (\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m),]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m#print (objective_function([10,10,500,2], home_elo,away_elo,home_ratings, away_ratings))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Minimize the objective function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m optimize()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m result \u001b[39m=\u001b[39m minimize(objective_function, p0, args\u001b[39m=\u001b[39m(home_elo, away_elo, home_ratings, away_ratings),bounds\u001b[39m=\u001b[39mbounds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Extract the optimal k-factor\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import optimize\n",
    "\n",
    "\n",
    "# Define the Elo function\n",
    "def elo_function(home_rating, away_rating, K, HFA,c):\n",
    "    for index, row in season.iterrows():\n",
    "        update_elo(row['HomeTeam'], row['AwayTeam'], row['HomeScore'], row['AwayScore'], row['Home_xG'], row['Away_xG'], K, c)\n",
    "    merged_df = pd.merge(season_y, ratings_df, left_on='HomeTeam', right_on='team_name', how='left')\n",
    "\n",
    "    # Merge for away team's Elo rating\n",
    "    merged_df = pd.merge(merged_df, ratings_df, left_on='AwayTeam', right_on='team_name', how='left', suffixes=('_home', '_away'))\n",
    "\n",
    "    # Manually rename columns to avoid conflicts\n",
    "    merged_df.rename(columns={'elo_rating_home': 'home_elo_rating', 'reverse_rating_home': 'home_reverse_rating', 'difference_home': 'home_difference',\n",
    "                            'elo_rating_away': 'away_elo_rating', 'reverse_rating_away': 'away_reverse_rating', 'difference_away': 'away_difference'}, inplace=True)\n",
    "    odds = 1 / (1 + 10 ** (away_rating - (home_rating+HFA))/c)\n",
    "    #print (odds)\n",
    "    #print (odds)\n",
    "    return (odds)\n",
    "    # updated_home_rating = home_rating + K_adjusted * (S_home - E_home)\n",
    "    # updated_away_rating = away_rating + K_adjusted * (S_away - E_away)\n",
    "    \n",
    "    # # ratings[home_team] = updated_home_rating\n",
    "    # # ratings[away_team] = updated_away_rating\n",
    "    # xG_diff = home_rating - away_rating\n",
    "    # K_adjusted = K * (1 + abs(xG_diff) / b)\n",
    "    \n",
    "    \n",
    "    #return K_adjusted * (1 + expected_score / c)\n",
    "\n",
    "# Define the objective function (RMSE)\n",
    "\n",
    "def objective_function(params, home_elo, away_elo, home_ratings, away_ratings):\n",
    "    k, HFA_factor,c = params\n",
    "     \n",
    "    # E_home = (elo_home > elo_away) + 0.5 * (elo_home == elo_away)\n",
    "    # E_away = (elo_away > elo_home) + 0.5 * (elo_home == elo_away)\n",
    "    \n",
    "    E_home = elo_function(home_elo, away_elo, k, HFA_factor,c)\n",
    "    E_away = 1 - E_home\n",
    "    S_home = (home_ratings >away_ratings) + 0.5 * (home_ratings == away_ratings)\n",
    "    S_away = (away_ratings > home_ratings) + 0.5 * (home_ratings == away_ratings)\n",
    "    \n",
    "    \n",
    "    squared_errors = ((E_home - S_home) ** 2)\n",
    "    #print (squared_errors)\n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "home_ratings = merged_df[\"Home_xG\"]\n",
    "away_ratings = merged_df[\"Away_xG\"]\n",
    "home_elo = merged_df[\"EloRating_home\"]\n",
    "away_elo = merged_df[\"EloRating_away\"]\n",
    "\n",
    "# Initial guess for the k-factor\n",
    "p0 = [500, 500, 500]  # Initial guess for K, HFA, and c\n",
    "bounds = [(0, 1000), (0, 1000), (0, 1000),]\n",
    "\n",
    "#print (objective_function([10,10,500,2], home_elo,away_elo,home_ratings, away_ratings))\n",
    "\n",
    "# Minimize the objective function\n",
    "#optimize()\n",
    "result = minimize(objective_function, p0, args=(home_elo, away_elo, home_ratings, away_ratings),bounds=bounds)\n",
    "\n",
    "# Extract the optimal k-factor\n",
    "best_K, best_HFA_factor, best_c_factor = result.x\n",
    "#print(\"best_k_factor:\", best_k_factor)\n",
    "print(\"best_HFA_factor:\", best_HFA_factor)\n",
    "print (\"best_k:\", best_K)\n",
    "print(\"best_c_factor:\", best_c_factor)\n",
    "#print(\"best_b:\", best_b)\n",
    "print (\"rmse\", result.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII representation of the message:\n",
      "[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 33]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_rating(home=\"HomeTeam\", away=\"AwayTeam\", home_goals=\"FTHG\",\n",
    "               away_goals=\"FTAG\", data=None, k_factor=24, initial_rating=1500,\n",
    "               home_advantage=0):\n",
    "    \n",
    "    # Make a list to hold ratings for all teams\n",
    "    all_teams = list(set(data[home]).union(set(data[away])))\n",
    "    \n",
    "    ratings = {team: initial_rating for team in all_teams}\n",
    "    \n",
    "    # Loop through data and update ratings\n",
    "    for idx in range(len(data)):\n",
    "        # Get current ratings\n",
    "        home_team_name = data[home][idx]\n",
    "        away_team_name = data[away][idx]\n",
    "        home_team_rating = ratings[home_team_name] + home_advantage\n",
    "        away_team_rating = ratings[away_team_name]\n",
    "        \n",
    "        # Calculate expected outcome\n",
    "        expected_home = 1 / (1 + 10 ** ((away_team_rating - home_team_rating) / 400))\n",
    "        expected_away = 1 - expected_home\n",
    "        \n",
    "        # Observed outcome\n",
    "        goal_diff = data[home_goals][idx] - data[away_goals][idx]\n",
    "        if goal_diff == 0:\n",
    "            result_home = 0.5\n",
    "            result_away = 0.5\n",
    "        elif goal_diff < 0:\n",
    "            result_home = 0\n",
    "            result_away = 1\n",
    "        else:\n",
    "            result_home = 1\n",
    "            result_away = 0\n",
    "        \n",
    "        # Update ratings\n",
    "        ratings[home_team_name] += k_factor * (result_home - expected_home)\n",
    "        ratings[away_team_name] += k_factor * (result_away - expected_away)\n",
    "    \n",
    "    # Prepare output\n",
    "    ratings_out = sorted(ratings.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ratings_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m k_values_to_test \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m50\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Find optimal k-value\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m optimal_k, min_rmse \u001b[39m=\u001b[39m find_optimal_k(data, k_values_to_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimal K-value:\u001b[39m\u001b[39m\"\u001b[39m, optimal_k)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMinimum RMSE:\u001b[39m\u001b[39m\"\u001b[39m, min_rmse)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_rmse(predictions, targets):\n",
    "    return np.sqrt(mean_squared_error(predictions, targets))\n",
    "\n",
    "def find_optimal_k(data, k_values):\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        # Apply Elo rating function with current k-value\n",
    "        ratings = elo_rating(data=data, k_factor=k)\n",
    "        \n",
    "        # Compute RMSE\n",
    "        predicted_ratings = [rating[1] for rating in ratings]\n",
    "        actual_ratings = [actual_rating[1] for actual_rating in actual_ratings_list]\n",
    "        rmse = calculate_rmse(predicted_ratings, actual_ratings)\n",
    "        rmse_scores.append((k, rmse))\n",
    "    \n",
    "    # Fit linear regression model\n",
    "    X = np.array([score[0] for score in rmse_scores]).reshape(-1, 1)\n",
    "    y = np.array([score[1] for score in rmse_scores])\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X, y)\n",
    "    \n",
    "    # Predict RMSE for a wide range of k-values\n",
    "    k_values_range = np.linspace(min(k_values), max(k_values), 100).reshape(-1, 1)\n",
    "    predicted_rmse = regression_model.predict(k_values_range)\n",
    "    \n",
    "    # Find k-value that minimizes predicted RMSE\n",
    "    optimal_k_idx = np.argmin(predicted_rmse)\n",
    "    optimal_k = k_values_range[optimal_k_idx][0]\n",
    "    \n",
    "    return optimal_k, predicted_rmse[optimal_k_idx][0]\n",
    "\n",
    "# Example usage\n",
    "# Define range of k-values to test\n",
    "k_values_to_test = range(10, 50)\n",
    "\n",
    "# Find optimal k-value\n",
    "optimal_k, min_rmse = find_optimal_k(data, k_values_to_test)\n",
    "print(\"Optimal K-value:\", optimal_k)\n",
    "print(\"Minimum RMSE:\", min_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_val: (378, 53)\n",
      "Shape of y_val: (378,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'matches' containing match data with columns ['HomeTeam', 'AwayTeam', 'Home_xG', 'Away_xG', 'HomeScore', 'AwayScore']\n",
    "# You would replace this with your actual dataset\n",
    "\n",
    "# Example code to prepare X_val and y_val\n",
    "def prepare_features(matches):\n",
    "    \"\"\"\n",
    "    Prepare features (X_val) for the validation set.\n",
    "    \"\"\"\n",
    "    # Extract relevant features\n",
    "    X_val = matches[['HomeTeam', 'AwayTeam', 'Home_xG', 'Away_xG']]\n",
    "    \n",
    "    # Example: Convert team names to one-hot encoding\n",
    "    X_val = pd.get_dummies(X_val, columns=['HomeTeam', 'AwayTeam'])\n",
    "    \n",
    "    # You can include additional features like match location, match importance, etc.\n",
    "    \n",
    "    return X_val\n",
    "\n",
    "def prepare_target(matches):\n",
    "    \"\"\"\n",
    "    Prepare target variable (y_val) for the validation set.\n",
    "    \"\"\"\n",
    "    # Determine match outcomes (1 for home team win, 0 for home team loss)\n",
    "    y_val = (matches['HomeScore'] > matches['AwayScore']).astype(int)\n",
    "    \n",
    "    return y_val\n",
    "\n",
    "# Example usage:\n",
    "# Load match data into DataFrame 'matches'\n",
    "\n",
    "\n",
    "# Prepare features and target variable for the validation set\n",
    "X_val = prepare_features(season_X)\n",
    "y_val = prepare_target(season_X)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Home Advantage: 400\n",
      "Best K: 0.0\n",
      "Best Constant: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(matches, home_advantage, K, constant):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error for a given set of matches, home advantage, K value, and constant term.\n",
    "    \"\"\"\n",
    "    squared_errors = []\n",
    "    ratings = {}  # Reset ratings for each calculation\n",
    "    for index, match in matches.iterrows():\n",
    "        home_team, away_team = match['HomeTeam'], match['AwayTeam']\n",
    "        home_rating, away_rating = ratings.get(home_team, INITIAL_RATING), ratings.get(away_team, INITIAL_RATING)\n",
    "        home_xG, away_xG = match['Home_xG'], match['Away_xG']\n",
    "        home_score, away_score = match['HomeScore'], match['AwayScore']\n",
    "        \n",
    "        adjusted_home_rating = home_rating + home_advantage\n",
    "        \n",
    "        E_home = 1 / (1 + 10 ** ((away_rating - adjusted_home_rating) / constant))\n",
    "        E_away = 1 - E_home\n",
    "\n",
    "        # Determine actual score\n",
    "        S_home, S_away = (1, 0) if home_xG > away_xG else (0, 1) if home_xG < away_xG else (0.5, 0.5)\n",
    "        \n",
    "        # Calculate xG difference and adjust K factor\n",
    "        xG_diff = home_xG - away_xG\n",
    "        K_adjusted = K * (1 + xG_diff / 2)  # Example adjustment, modify as needed\n",
    "        \n",
    "        # Update ratings\n",
    "        updated_home_rating = home_rating + K_adjusted * (S_home - E_home)\n",
    "        updated_away_rating = away_rating + K_adjusted * (S_away - E_away)\n",
    "        \n",
    "        ratings[home_team] = updated_home_rating\n",
    "        ratings[away_team] = updated_away_rating\n",
    "        \n",
    "        # Calculate squared error\n",
    "        squared_error_home = (E_home - S_home) ** 2\n",
    "        squared_error_away = (E_away - S_away) ** 2\n",
    "        squared_errors.append(squared_error_home + squared_error_away)\n",
    "    \n",
    "    return sum(squared_errors) / len(matches)\n",
    "\n",
    "\n",
    "INITIAL_RATING = 1500\n",
    "\n",
    "# Define ranges for HOME_ADVANTAGE, K, and the constant term\n",
    "home_advantage_values = np.arange(150, 200, 1)\n",
    "K_values = np.arange(0, 20, 0.1)\n",
    "constant_values = np.arange(350, 500, 1)\n",
    "\n",
    "best_rmse = float('inf')  # Initialize with a large value\n",
    "best_home_advantage = None\n",
    "best_K = None\n",
    "best_constant = None\n",
    "RMSE_values = []\n",
    "\n",
    "for K in K_values:\n",
    "        # for constant in constant_values:\n",
    "        mse = mean_squared_error(season_X, 400, K, 2)\n",
    "        #     RMSE_values.append(mse)\n",
    "        if mse < best_rmse:\n",
    "            best_rmse = mse\n",
    "            best_home_advantage = 400\n",
    "            best_K = K\n",
    "            best_constant = 2\n",
    "#for home_advantage in home_advantage_values:\n",
    "    \n",
    "\n",
    "print(\"Best Home Advantage:\", best_home_advantage)\n",
    "print(\"Best K:\", best_K)\n",
    "print(\"Best Constant:\", best_constant)\n",
    "\n",
    "plt.plot(RMSE_values)\n",
    "plt.title('RMSE Values')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "def bradley_terry_prob(r_i, r_j, h, c):\n",
    "    return 1 / (1 + np.exp((r_j - (r_i + h)) / c))\n",
    "\n",
    "def update_rating(r_i, r_j, xg_diff, s_i, e_i, k, d):\n",
    "\n",
    "    adjustment = k * (1 + xg_diff / d) * (e_i - s_i)\n",
    "    return r_i + adjustment\n",
    "\n",
    "def calculate_rmse(predictions, actuals):\n",
    "    return np.sqrt(np.mean((predictions - actuals) ** 2))\n",
    "\n",
    "def optimize_parameters(train_data, initial_params):\n",
    "    def objective(params):\n",
    "        h, c, k, d = params\n",
    "        team_ratings = {team: 1500 for team in train_data['team_1'].unique()}\n",
    "        predictions = []\n",
    "\n",
    "        for _, match in train_data.iterrows():\n",
    "            r_i = team_ratings[match['team_1']]\n",
    "            r_j = team_ratings[match['team_2']]\n",
    "\n",
    "\n",
    "            s_i = bradley_terry_prob(r_i, r_j, h, c)\n",
    "            xg_diff = match['xG_1'] - match['xG_2']\n",
    "            e_i = match['result']  # 1 for win, 0.5 for draw, 0 for loss\n",
    "\n",
    "            team_ratings[match['team_1']] = update_rating(r_i, r_j, xg_diff, s_i, e_i, k, d)\n",
    "            team_ratings[match['team_2']] = update_rating(r_j, r_i, -xg_diff, 1-s_i, 1-e_i, k, d)\n",
    "\n",
    "            predictions.append(s_i)\n",
    "\n",
    "        return calculate_rmse(np.array(predictions), train_data['result'].values)\n",
    "\n",
    "    result = minimize(objective, initial_params, method='Nelder-Mead')\n",
    "    return result.x\n",
    "\n",
    "def whole_history_rating(data, params):\n",
    "    h, c, k, d = params\n",
    "    team_ratings = {team: 1500 for team in data['team_1'].unique()}\n",
    "\n",
    "    for _, match in data.iterrows():\n",
    "        r_i = team_ratings[match['team_1']]\n",
    "        r_j = team_ratings[match['team_2']]\n",
    "\n",
    "        # Calculate win probability and update ratings\n",
    "        s_i = bradley_terry_prob(r_i, r_j, h, c)\n",
    "        xg_diff = match['xG_1'] - match['xG_2']\n",
    "        e_i = match['result']  # 1 for win, 0.5 for draw, 0 for loss\n",
    "\n",
    "        team_ratings[match['team_1']] = update_rating(r_i, r_j, xg_diff, s_i, e_i, k, d)\n",
    "        team_ratings[match['team_2']] = update_rating(r_j, r_i, -xg_diff, 1-s_i, 1-e_i, k, d)\n",
    "\n",
    "    return team_ratings\n",
    "# Sample Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dataset: Replace this with your actual dataset\n",
    "    data = pd.DataFrame({\n",
    "        'team_1': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "        'team_2': ['B', 'C', 'A', 'C', 'A', 'B'],\n",
    "        'xG_1': [1.5, 2.0, 1.2, 1.8, 1.0, 1.6],\n",
    "        'xG_2': [1.2, 1.8, 1.5, 1.3, 1.6, 1.1],\n",
    "        'result': [1, 0.5, 0, 1, 0, 0.5]  # 1 for win, 0.5 for draw, 0 for loss\n",
    "    })\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    train_data = data.iloc[:4]\n",
    "    test_data = data.iloc[4:]\n",
    "\n",
    "    # Initial parameters: [h, c, k, d]\n",
    "    initial_params = [30, 400, 16, 2]\n",
    "\n",
    "    # Optimize parameters\n",
    "    optimized_params = optimize_parameters(train_data, initial_params)\n",
    "    print(\"Optimized Parameters:\", optimized_params)\n",
    "\n",
    "    # Calculate ratings using the whole-history model\n",
    "    final_ratings = whole_history_rating(data, optimized_params)\n",
    "    print(\"Final Team Ratings:\", final_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HomeTeam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HomeTeam'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m initial_k \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# Define bounds for K if necessary\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# bounds = [(lower_bound, upper_bound)]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# Minimize the objective function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m result \u001b[39m=\u001b[39m minimize(objective_function, initial_k, args\u001b[39m=\u001b[39;49m(X_train, y_train, X_val, y_val), method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mNelder-Mead\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39m# Get the best K value\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m best_k \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mx[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/scipy/optimize/_minimize.py:698\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    695\u001b[0m callback \u001b[39m=\u001b[39m _wrap_callback(callback, meth)\n\u001b[1;32m    697\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnelder-mead\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 698\u001b[0m     res \u001b[39m=\u001b[39m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    699\u001b[0m                                \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    700\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpowell\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    701\u001b[0m     res \u001b[39m=\u001b[39m _minimize_powell(fun, x0, args, callback, bounds, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/scipy/optimize/_optimize.py:899\u001b[0m, in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 899\u001b[0m         fsim[k] \u001b[39m=\u001b[39m func(sim[k])\n\u001b[1;32m    900\u001b[0m \u001b[39mexcept\u001b[39;00m _MaxFuncCallError:\n\u001b[1;32m    901\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/scipy/optimize/_optimize.py:620\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    618\u001b[0m ncalls[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    619\u001b[0m \u001b[39m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m fx \u001b[39m=\u001b[39m function(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49m(wrapper_args \u001b[39m+\u001b[39;49m args))\n\u001b[1;32m    621\u001b[0m \u001b[39m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[39m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mObjective function to minimize - returns the value of the evaluation metric.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# Fit Elo ratings using the current K value on the training set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m elo_ratings \u001b[39m=\u001b[39m fit_elo(params, X_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Predict match outcomes on the validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict_elo(elo_ratings, X_val)\n",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m K, \u001b[39m=\u001b[39m params\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Initialize ratings dictionary with initial ratings for all teams\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m ratings \u001b[39m=\u001b[39m {team: initial_rating \u001b[39mfor\u001b[39;00m team \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(matches[\u001b[39m'\u001b[39;49m\u001b[39mHomeTeam\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39munion(matches[\u001b[39m'\u001b[39m\u001b[39mAwayTeam\u001b[39m\u001b[39m'\u001b[39m])}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Iterate over matches and update ratings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, match \u001b[39min\u001b[39;00m matches\u001b[39m.\u001b[39miterrows():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HomeTeam'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def elo_expected_score(home_rating, away_rating):\n",
    "\n",
    "    home_expected_score = 1 / (1 + 10 ** ((away_rating - home_rating) / 400))\n",
    "    away_expected_score = 1 - home_expected_score\n",
    "    return home_expected_score, away_expected_score\n",
    "\n",
    "def update_elo_ratings(home_rating, away_rating, home_xG, away_xG, home_score, away_score, k):\n",
    "    home_expected_score, away_expected_score = elo_expected_score(home_rating, away_rating)\n",
    "    \n",
    "    # Update ratings\n",
    "    home_new_rating = home_rating + k * (home_score - home_expected_score)\n",
    "    away_new_rating = away_rating + k * (away_score - away_expected_score)\n",
    "    \n",
    "    return home_new_rating, away_new_rating\n",
    "\n",
    "\n",
    "def calculate_metric(predictions, actual_outcomes):\n",
    "\n",
    "    # Implement your metric calculation here (e.g., mean squared error)\n",
    "    # Return the calculated metric\n",
    "    pass\n",
    "\n",
    "def fit_elo(params, matches, initial_rating=1500):\n",
    "    # Unpack parameters\n",
    "    K, = params\n",
    "    \n",
    "    # Initialize ratings dictionary with initial ratings for all teams\n",
    "    ratings = {team: initial_rating for team in set(matches['HomeTeam']).union(matches['AwayTeam'])}\n",
    "    \n",
    "    # Iterate over matches and update ratings\n",
    "    for index, match in matches.iterrows():\n",
    "        home_team, away_team = match['HomeTeam'], match['AwayTeam']\n",
    "        home_xG, away_xG = match['Home_xG'], match['Away_xG']\n",
    "        home_score, away_score = match['HomeScore'], match['AwayScore']\n",
    "        \n",
    "        home_rating, away_rating = ratings[home_team], ratings[away_team]\n",
    "        \n",
    "        # Calculate expected scores\n",
    "        home_expected_score, away_expected_score = elo_expected_score(home_rating, away_rating)\n",
    "        \n",
    "        # Determine actual scores\n",
    "        if home_score > away_score:\n",
    "            home_score, away_score = 1, 0\n",
    "        elif home_score < away_score:\n",
    "            home_score, away_score = 0, 1\n",
    "        else:\n",
    "            home_score, away_score = 0.5, 0.5\n",
    "        \n",
    "        # Update ratings\n",
    "        ratings[home_team], ratings[away_team] = update_elo_ratings(home_rating, away_rating, home_xG, away_xG, home_score, away_score, K)\n",
    "    \n",
    "    return ratings\n",
    "\n",
    "def objective_function(params, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    # Fit Elo ratings using the current K value on the training set\n",
    "    elo_ratings = fit_elo(params, X_train)\n",
    "    \n",
    "    # Predict match outcomes on the validation set\n",
    "    predictions = predict_elo(elo_ratings, X_val)\n",
    "    \n",
    "    # Calculate the evaluation metric\n",
    "    metric = calculate_metric(predictions, y_val)\n",
    "    \n",
    "    return metric\n",
    "\n",
    "# Initial guess for the K value\n",
    "initial_k = 32\n",
    "\n",
    "# Define bounds for K if necessary\n",
    "# bounds = [(lower_bound, upper_bound)]\n",
    "\n",
    "# Minimize the objective function\n",
    "result = minimize(objective_function, initial_k, args=(X_train, y_train, X_val, y_val), method='Nelder-Mead')\n",
    "\n",
    "# Get the best K value\n",
    "best_k = result.x[0]\n",
    "\n",
    "print(\"Best K value:\", best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume 'season' DataFrame is previously defined\n",
    "\n",
    "# Initialize teams and ratings\n",
    "teams = np.unique(np.concatenate([season['HomeTeam'], season['AwayTeam']]))\n",
    "ratings = {str(team): 1500 for team in teams}\n",
    "\n",
    "def mean_squared_error(K, HFA, c, matches):\n",
    "    squared_errors = []\n",
    "    for _, match in matches.iterrows():\n",
    "        home_team = str(match['HomeTeam'])\n",
    "        away_team = str(match['AwayTeam'])\n",
    "        home_rating = ratings[home_team]\n",
    "        away_rating = ratings[away_team]\n",
    "\n",
    "        adjusted_home_rating = home_rating + HFA\n",
    "        E_home = 1 / (1 + 10 ** ((away_rating - adjusted_home_rating) / c))\n",
    "        E_away = 1 - E_home\n",
    "\n",
    "        home_score = match['HomeScore']\n",
    "        away_score = match['AwayScore']\n",
    "        xG_diff = match['Home_xG'] - match['Away_xG']\n",
    "        K_adjusted = K * (1 + xG_diff / 2)  \n",
    "        S_home = 1 if home_score > away_score else 0 if home_score < away_score else 0.5\n",
    "        S_away = 1 - S_home\n",
    "        updated_home_rating = home_rating + K_adjusted * (S_home - E_home)\n",
    "        updated_away_rating = away_rating + K_adjusted * (S_away - E_away)\n",
    "        \n",
    "        ratings[home_team] = updated_home_rating\n",
    "        ratings[away_team] = updated_away_rating\n",
    "\n",
    "        squared_error = ((E_home - S_home) ** 2 + (E_away - S_away) ** 2)\n",
    "        squared_errors.append(squared_error)\n",
    "\n",
    "    return np.mean(squared_errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(x, K, HFA, c,):\n",
    "    squared_errors = []\n",
    "    for _, match in season_X.iterrows():\n",
    "        home_team = str(match['HomeTeam'])\n",
    "        away_team = str(match['AwayTeam'])\n",
    "        home_rating = ratings[home_team]\n",
    "        away_rating = ratings[away_team]\n",
    "\n",
    "        x = x - HFA\n",
    "        E_home = 1 / (1 + 10 ** (x / c))\n",
    "        E_away = 1 - E_home\n",
    "\n",
    "        home_score = match['HomeScore']\n",
    "        away_score = match['AwayScore']\n",
    "        xG_diff = match['Home_xG'] - match['Away_xG']\n",
    "        K_adjusted = K * (1 + xG_diff / 2)  \n",
    "        S_home = 1 if home_score > away_score else 0 if home_score < away_score else 0.5\n",
    "        S_away = 1 - S_home\n",
    "        updated_home_rating = home_rating + K_adjusted * (S_home - E_home)\n",
    "        updated_away_rating = away_rating + K_adjusted * (S_away - E_away)\n",
    "        \n",
    "        ratings[home_team] = updated_home_rating\n",
    "        ratings[away_team] = updated_away_rating\n",
    "\n",
    "        squared_error = ((E_home - S_home) ** 2 + (E_away - S_away) ** 2)\n",
    "        squared_errors.append(squared_error)\n",
    "\n",
    "    return np.mean(squared_errors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# Initialize teams and ratings using dictionaries for faster access\n",
    "teams = np.unique(np.concatenate([season_X['HomeTeam'], season_X['AwayTeam']]))\n",
    "# home_ratings = np.array([ratings[team] for team in season_X['HomeTeam']])\n",
    "# away_ratings = np.array([ratings[team] for team in season_X['AwayTeam']])\n",
    "\n",
    "def mean_squared_error(params, matches):\n",
    "    K, HFA, c, bCons = params\n",
    "    # Calculate adjusted home ratings\n",
    "    adjusted_home_ratings = matches['Home_xG'] + HFA\n",
    "    \n",
    "    # Calculate expected outcomes\n",
    "    E_home = 1 / (1 + 10 ** ((matches['Away_xG'] - adjusted_home_ratings) / c))\n",
    "    E_away = 1 - E_home\n",
    "    \n",
    "    \n",
    "    S_home = (matches['Home_xG'] > matches['Away_xG']) + 0.5 * (matches['Home_xG'] == matches['Away_xG'])\n",
    "    S_away = (matches['Away_xG'] > matches['Home_xG']) + 0.5 * (matches['Home_xG'] == matches['Away_xG'])\n",
    "    \n",
    "\n",
    "# def mean_squared_error(params, matches):\n",
    "#     # Calculate squared errors\n",
    "#     squared_errors = ((E_home - S_home) ** 2 + (E_away - S_away) ** 2)\n",
    "    \n",
    "#     # Return mean squared error\n",
    "#     return np.sqrt(np.mean(squared_errors))\n",
    "\n",
    "\n",
    "\n",
    "# def mean_squared_error(params, matches):\n",
    "#     \"\"\"\n",
    "#     Calculate the mean squared error for a given set of matches and K value.\n",
    "#     \"\"\"\n",
    "#     squared_errors = []\n",
    "#     K, HFA, c, bCons = params\n",
    "#     for index, row in matches.iterrows():\n",
    "#         match = season.iloc[index]\n",
    "#         home_team, away_team = match['HomeTeam'], match['AwayTeam']\n",
    "#         home_rating, away_rating = ratings.get(home_team, INITIAL_RATING), ratings.get(away_team, INITIAL_RATING)\n",
    "#         home_xG, away_xG = match['Home_xG'], match['Away_xG']\n",
    "#         home_score, away_score = match['HomeScore'], match['AwayScore']\n",
    "        \n",
    "#         adjusted_home_rating = home_rating + params\n",
    "        \n",
    "#         E_home = 1 / (1 + 10 ** ((away_rating - adjusted_home_rating) / 400))\n",
    "#         E_away = 1 - E_home\n",
    "\n",
    "#         # Determine actual score\n",
    "#         S_home, S_away = (1, 0) if home_xG > away_xG else (0, 1) if home_xG < away_xG else (0.5, 0.5)\n",
    "        \n",
    "#         # Calculate xG difference and adjust K factor\n",
    "#         xG_diff = home_xG - away_xG\n",
    "#         K_adjusted = K * (1 + xG_diff / 2)  # Example adjustment, modify as needed\n",
    "        \n",
    "#         # Update ratings\n",
    "#         updated_home_rating = home_rating + K_adjusted * (S_home - E_home)\n",
    "#         updated_away_rating = away_rating + K_adjusted * (S_away - E_away)\n",
    "        \n",
    "#         ratings[home_team] = updated_home_rating\n",
    "#         ratings[away_team] = updated_away_rating\n",
    "        \n",
    "#         # Calculate squared error\n",
    "#         squared_error_home = (E_home - S_home) ** 2\n",
    "#         squared_error_away = (E_away - S_away) ** 2\n",
    "#         squared_errors.append(squared_error_home + squared_error_away)\n",
    "    \n",
    "#     return sum(squared_errors) / len(matches)\n",
    "\n",
    "# INITIAL_RATING = 1500\n",
    "\n",
    "# Fit the mean squared error function to the data\n",
    "# p0 = [10, 10, 500, 0]  # Initial guess for K, HFA, and c\n",
    "# bounds = [(0, None), (0, None), (0, None), (0, None)]\n",
    "# result = minimize(mean_squared_error, p0, args=(season_X,), bounds=bounds)\n",
    "\n",
    "# # Extract the optimized values\n",
    "# best_K, best_HFA, best_c, best_b = result.x\n",
    "# best_rmse = result.fun\n",
    "\n",
    "# print(\"RMSE for best values:\", best_rmse)\n",
    "# print(\"Best K:\", best_K)\n",
    "# print(\"Best Home Field Advantage:\", best_HFA)\n",
    "# print(\"Best c:\", best_c)\n",
    "# print(\"Best b:\", best_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'HFA' for estimator DummyEstimator(). Valid parameters are: [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Perform grid search\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Get the best parameters and RMSE\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    718\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 720\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mset_params(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcloned_parameters)\n\u001b[1;32m    722\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    724\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/base.py:229\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_params:\n\u001b[1;32m    228\u001b[0m     local_valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid parameters are: \u001b[39m\u001b[39m{\u001b[39;00mlocal_valid_params\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m delim:\n\u001b[1;32m    235\u001b[0m     nested_params[key][sub_key] \u001b[39m=\u001b[39m value\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'HFA' for estimator DummyEstimator(). Valid parameters are: []."
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.base import BaseEstimator, RegressorMixin\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Define the custom dummy estimator\n",
    "# class DummyEstimator(BaseEstimator, RegressorMixin):\n",
    "#     def fit(self, X, y):\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return X\n",
    "\n",
    "# # Wrapper function for mean_squared_error to use with GridSearchCV\n",
    "# def rmse_scorer(y_true, y_pred):\n",
    "#     return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'K': np.arange(0, 20, 0.1),\n",
    "#     'HFA': np.arange(0, 200, 1),\n",
    "#     'c': np.arange(300, 500, 1),\n",
    "#     'bCons': [True, False]  # Example of binary parameter\n",
    "# }\n",
    "\n",
    "# # Instantiate GridSearchCV with your model (here we're using the dummy model)\n",
    "# grid_search = GridSearchCV(estimator=DummyEstimator(), param_grid=param_grid, scoring=make_scorer(rmse_scorer, greater_is_better=False), cv=5)\n",
    "\n",
    "# # Split your data into features (X) and target (y)\n",
    "# X = season_X[['Home_xG', 'Away_xG']]  # Example feature columns\n",
    "# y = season_X[['HomeScore', 'AwayScore']]  # Example target columns\n",
    "\n",
    "# # Train-test split (you should adjust this according to your data)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Get the best parameters and RMSE\n",
    "# best_params = grid_search.best_params_\n",
    "# best_rmse = np.abs(grid_search.best_score_)  # RMSE is negative in GridSearchCV, so take absolute value\n",
    "\n",
    "# print(\"Best parameters:\", best_params)\n",
    "# print(\"Best RMSE:\", best_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {team: 1500 for team in teams}\n",
    "def update (matches, K, HFA, c):\n",
    "    adjusted_home_ratings = matches['Home_xG'] + HFA\n",
    "    \n",
    "    # Calculate expected outcomes\n",
    "    E_home = 1 / (1 + 10 ** ((matches['Away_xG'] - adjusted_home_ratings) / c))\n",
    "    E_away = 1 - E_home\n",
    "    \n",
    "    S_home = (matches['Home_xG'] > matches['Away_xG']) + 0.5 * (matches['Home_xG'] == matches['Away_xG'])\n",
    "    S_away = (matches['Away_xG'] > matches['Home_xG']) + 0.5 * (matches['Home_xG'] == matches['Away_xG'])\n",
    "    \n",
    "    xG_diff = matches['Home_xG'] - matches['Away_xG']\n",
    "    K_adjusted = K * (1 + xG_diff / 500000) \n",
    "    updated_home_ratings = adjusted_home_ratings + K_adjusted * (S_home - E_home)\n",
    "    updated_away_ratings = matches['Away_xG'] + K_adjusted * (S_away - E_away)\n",
    "    \n",
    "    for i, team in enumerate(matches['HomeTeam']):\n",
    "        ratings[team] = updated_home_ratings[i]\n",
    "    for i, team in enumerate(matches['AwayTeam']):\n",
    "        ratings[team] = updated_away_ratings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ratings \u001b[39m=\u001b[39m ratings_forward\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m season_y\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     update(row,best_K, best_HFA, best_c)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Update ratings_reverse with the reverse iteration\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ratings \u001b[39m=\u001b[39m ratings_reverse\n",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m updated_away_ratings \u001b[39m=\u001b[39m matches[\u001b[39m'\u001b[39m\u001b[39mAway_xG\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m K_adjusted \u001b[39m*\u001b[39m (S_away \u001b[39m-\u001b[39m E_away)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, team \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matches[\u001b[39m'\u001b[39m\u001b[39mHomeTeam\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     ratings[team] \u001b[39m=\u001b[39m updated_home_ratings[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, team \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matches[\u001b[39m'\u001b[39m\u001b[39mAwayTeam\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     ratings[team] \u001b[39m=\u001b[39m updated_away_ratings[i]\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "ratings_forward = {team: 1500 for team in teams}\n",
    "ratings_reverse = {team: 1500 for team in teams}\n",
    "ratings = ratings_forward\n",
    "for index, row in season_y.iterrows():\n",
    "    update(row,best_K, best_HFA, best_c)\n",
    "\n",
    "# Update ratings_reverse with the reverse iteration\n",
    "ratings = ratings_reverse\n",
    "for index in range(season_y.shape[0] - 1, -1, -1):\n",
    "    row = season_y.iloc[index]\n",
    "    update(row, best_K, best_HFA, best_c)\n",
    "\n",
    "# Create a DataFrame to store both sets of ratings and calculate the difference\n",
    "ratings_df = pd.DataFrame(index=teams, columns=['EloRating', 'Reverse Rating', 'Difference'])\n",
    "for team in teams:\n",
    "    ratings_df.at[team, 'EloRating'] = ratings_forward[team]\n",
    "    ratings_df.at[team, 'Reverse Rating'] = ratings_reverse[team]\n",
    "    ratings_df.at[team, 'Difference'] = ratings_forward[team] - ratings_reverse[team]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate goal difference\n",
    "season_X['GoalDiff'] = season_X['Home_xG'] - season_X['Away_xG']\n",
    "\n",
    "# Plot relationship between goal difference and outcome\n",
    "plt.scatter(season_X['GoalDiff'], season_X['Result'])\n",
    "plt.xlabel('Goal Difference (Home - Away)')\n",
    "plt.ylabel('Outcome')\n",
    "plt.title('Relationship between Goal Difference and Outcome')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(HFA_values)):\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(c_values)):\n\u001b[0;32m---> 20\u001b[0m             rmses[i, j, k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt( \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAwayTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHomeScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAwayScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHome_xG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAway_xG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Plot 3D surface\u001b[39;00m\n\u001b[1;32m     23\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(params, matches)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(params, matches):\n\u001b[0;32m---> 12\u001b[0m     K, HFA, c, bCons \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Calculate adjusted home ratings\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     adjusted_home_ratings \u001b[38;5;241m=\u001b[39m matches[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHome_xG\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m HFA\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define the range of values for K, HFA, and c\n",
    "K_values = np.linspace(0, 10, 10)\n",
    "HFA_values = np.linspace(0, 10, 10)\n",
    "c_values = np.linspace(300, 600, 10)\n",
    "\n",
    "# Create meshgrid for the variables\n",
    "K_mesh, HFA_mesh, c_mesh = np.meshgrid(K_values, HFA_values, c_values, indexing='ij')\n",
    "\n",
    "# Initialize an array to store the RMSE values\n",
    "rmses = np.zeros_like(K_mesh)\n",
    "\n",
    "# Calculate RMSE for each combination of K, HFA, and c\n",
    "for i in range(len(K_values)):\n",
    "    for j in range(len(HFA_values)):\n",
    "        for k in range(len(c_values)):\n",
    "            rmses[i, j, k] = np.sqrt( mean_squared_error(K_values[i], season[['HomeTeam', 'AwayTeam', 'HomeScore', 'AwayScore', 'Home_xG', 'Away_xG']],))\n",
    "\n",
    "# Plot 3D surface\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Flatten the arrays\n",
    "K_flat = K_mesh.flatten()\n",
    "HFA_flat = HFA_mesh.flatten()\n",
    "c_flat = c_mesh.flatten()\n",
    "rmses_flat = rmses.flatten()\n",
    "\n",
    "# Plot the surface\n",
    "surf = ax.plot_trisurf(K_flat, HFA_flat, rmses_flat, cmap='viridis')\n",
    "\n",
    "# Add color bar\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "ax.set_xlabel('K-factor')\n",
    "ax.set_ylabel('Capabilities weight')\n",
    "ax.set_zlabel('Breakdown weight')\n",
    "ax.set_title('RMSE vs K-factor, Capabilities weight, and ')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'season' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Assume 'season' DataFrame is previously defined\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Initialize teams and ratings using dictionaries for faster access\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m teams \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate([season[\u001b[39m'\u001b[39m\u001b[39mHomeTeam\u001b[39m\u001b[39m'\u001b[39m], season[\u001b[39m'\u001b[39m\u001b[39mAwayTeam\u001b[39m\u001b[39m'\u001b[39m]]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ratings \u001b[39m=\u001b[39m {team: \u001b[39m1500\u001b[39m \u001b[39mfor\u001b[39;00m team \u001b[39min\u001b[39;00m teams}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/johnxu/Documents/VSCode/HiCMC/Class4/wharton.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m home_ratings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([ratings[team] \u001b[39mfor\u001b[39;00m team \u001b[39min\u001b[39;00m season[\u001b[39m'\u001b[39m\u001b[39mHomeTeam\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'season' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assume 'season' DataFrame is previously defined\n",
    "\n",
    "# Initialize teams and ratings using dictionaries for faster access\n",
    "teams = np.unique(np.concatenate([season['HomeTeam'], season['AwayTeam']]))\n",
    "ratings = {team: 1500 for team in teams}\n",
    "home_ratings = np.array([ratings[team] for team in season['HomeTeam']])\n",
    "away_ratings = np.array([ratings[team] for team in season['AwayTeam']])\n",
    "\n",
    "def mean_squared_error(K, HFA, c, matches):\n",
    "    # Calculate adjusted home ratings\n",
    "    adjusted_home_ratings = home_ratings + HFA\n",
    "    \n",
    "    # Calculate expected outcomes\n",
    "    E_home = 1 / (1 + 10 ** ((away_ratings - adjusted_home_ratings) / c))\n",
    "    E_away = 1 - E_home\n",
    "    \n",
    "    # Calculate K-factor adjustment based on goal difference\n",
    "    xG_diff = matches['Home_xG'] - matches['Away_xG']\n",
    "    K_adjusted = K * (1 + abs( xG_diff) / 2)  \n",
    "    \n",
    "    # Determine actual outcomes\n",
    "    S_home = matches['HomeScore'] > matches['AwayScore']\n",
    "    S_away = matches['AwayScore'] > matches['HomeScore']\n",
    "    \n",
    "    # Update ratings\n",
    "    updated_home_ratings = home_ratings + K_adjusted * (S_home - E_home)\n",
    "    updated_away_ratings = away_ratings + K_adjusted * (S_away - E_away)\n",
    "    \n",
    "    # Update ratings dictionary\n",
    "    for i, team in enumerate(matches['HomeTeam']):\n",
    "        ratings[team] = updated_home_ratings[i]\n",
    "    for i, team in enumerate(matches['AwayTeam']):\n",
    "        ratings[team] = updated_away_ratings[i]\n",
    "    \n",
    "    # Calculate squared errors\n",
    "    squared_errors = ((E_home - S_home) ** 2 + (E_away - S_away) ** 2)\n",
    "    \n",
    "    # Return mean squared error\n",
    "    return np.mean(squared_errors)\n",
    "\n",
    "# Example usage:\n",
    "# mse = mean_squared_error(K_value, HFA_value, c_value, season)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
